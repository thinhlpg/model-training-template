deepspeed run_template.py\
    --deepspeed="configs/ds_config_zero0.json"\
    --do_train\
    --do_eval\
    --resume_from_checkpoint="last-checkpoint"\
    --full_determinism\
    --use_fast_tokenizer\
    --model_name_or_path="t5-small"\
    --use_lora\
    --fp16\
    --train_file="/home/thinhlpg/data/ELI5/el5_vi_val.jsonl"\
    --eval_file="/home/thinhlpg/data/ELI5/el5_vi_val.jsonl"\
    --seed=42\
    --dataloader_num_workers=4\
    --output_dir="./output"\
    --num_train_epochs=1\
    --per_device_train_batch_size=4\
    --per_device_eval_batch_size=4\
    --gradient_accumulation_steps=8\
    --group_by_length\
    --learning_rate=2e-5\
    --weight_decay=0.001\
    --predict_with_generate\
    --generation_num_beams=4\
    --generation_max_length=512\
    --logging_strategy="steps"\
    --logging_steps=4\
    --logging_first_step\
    --log_level="debug"\
    --log_level_replica="error"\
    --save_strategy="steps"\
    --save_steps=8\
    --save_total_limit=3\
    --load_best_model_at_end\
    --evaluation_strategy="steps"\
    --eval_steps=8\
    --max_eval_samples=8\
    --metric_for_best_model="eval_loss"\
    --report_to="tensorboard"\
    --push_to_hub\
    --hub_private_repo\
    --hub_strategy="checkpoint"\